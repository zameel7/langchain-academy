{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Hi Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-e8bc382c-c2ae-44ac-b13c-d15782e914ec-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It's great to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How can I assist you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: __start__. Type: on_chain_start. Name: __start__\n",
      "Node: __start__. Type: on_chain_end. Name: __start__\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: _write\n",
      "Node: conversation. Type: on_chain_end. Name: _write\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' American', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Area', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' compete', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Here', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' key', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' points', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' History', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Founded', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' charter', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' All', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-Amer', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ica', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='AA', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' joined', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' leagues', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' merged', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Name', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' name', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\"', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' reference', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' prospect', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ors', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' arrived', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Northern', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' during', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='184', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Gold', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Rush', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Ach', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ievements', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Super', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='X', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='VI', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='III', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='IV', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=').\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Conference', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Championship', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' seven', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' times', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Division', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Not', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Figures', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Joe', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' four', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' victories', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Jerry', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Wid', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ely', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' considered', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' greatest', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' wide', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' receiver', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Steve', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Another', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' victory', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Bill', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Legendary', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' coach', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' developing', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' offense', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Home', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Le', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='vi', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Located', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' it', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' since', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Before', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' played', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Cand', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='lestick', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Park', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Masc', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ot', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Colors', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Red', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' gold', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' white', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Masc', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ot', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' S', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ourd', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ough', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Sam', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Recent', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Performance', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' experienced', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' various', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' levels', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' appearance', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Super', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' LIV', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' where', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' were', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' City', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Chiefs', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Ownership', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Management', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Owner', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Denise', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' De', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Bart', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='olo', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' York', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' John', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' York', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='CEO', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Jed', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' York', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='General', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Manager', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' John', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Lynch', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='Head', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Coach', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Kyle', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Shan', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ahan', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='as', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' latest', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=').\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Fan', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Base', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' widespread', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' often', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' referred', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='iner', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Empire', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.\"\\n\\n', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' iconic', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' contributions', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' game', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' particularly', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' through', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' innovative', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' strategies', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' introduced', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Bill', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, id='run-b4da8c01-94fb-498f-8236-778a21892a19')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The San Francisco 49ers are a professional American football team based in the San Francisco Bay Area. They compete in the National Football League (NFL) as a member of the league's National Football Conference (NFC) West division. The team was founded in 1946 as a charter member of the All-America Football Conference (AAFC) and joined the NFL in 1949 when the leagues merged.\n",
      "\n",
      "### Key Points:\n",
      "\n",
      "1. **Stadium**: The 49ers play their home games at Levi's Stadium in Santa Clara, California, which opened in 2014 and has a seating capacity of approximately 68,500. Before moving to Levi's Stadium, the team played at Candlestick Park in San Francisco.\n",
      "\n",
      "2. **Team Colors and Mascot**: The team's colors are red, gold, and white. Their mascot is Sourdough Sam, a character that represents a gold miner, reflecting the team's name which is derived from the prospectors who arrived in Northern California during the 1849 Gold Rush.\n",
      "\n",
      "3. **Championships**: The 49ers have a storied history and are one of the most successful teams in NFL history. They have won five Super Bowl championships (XVI, XIX, XXIII, XXIV, and XXIX), all of which were won between 1981 and 1994. They have also won numerous division titles and conference championships.\n",
      "\n",
      "4. **Notable Players**: The 49ers have had many legendary players, including:\n",
      "   - **Joe Montana**: Often considered one of the greatest quarterbacks of all time.\n",
      "   - **Jerry Rice**: Widely regarded as the greatest wide receiver in NFL history.\n",
      "   - **Steve Young**: Another Hall of Fame quarterback who led the team to a Super Bowl victory.\n",
      "   - **Ronnie Lott**: A Hall of Fame safety known for his hard-hitting style of play.\n",
      "   - **Frank Gore**: One of the NFL's all-time leading rushers.\n",
      "\n",
      "5. **Coaching and Management**: The team has been led by several notable head coaches, including Bill Walsh, who is credited with developing the \"West Coast Offense\" and leading the team to three Super Bowl victories. The current head coach (as of 2023) is Kyle Shanahan, who has been with the team since 2017. The general manager is John Lynch, a former NFL player and Hall of Famer.\n",
      "\n",
      "6. **Rivalries**: The 49ers have several intense rivalries, most notably with the Dallas Cowboys, Los Angeles Rams, and Seattle Seahawks. The rivalry with the Cowboys is particularly famous due to several high-stakes playoff matchups in the 1980s and 1990s.\n",
      "\n",
      "7. **Recent Performance**: In recent years, the 49ers have experienced a resurgence under the leadership of head coach Kyle Shanahan and general manager John Lynch. They reached Super Bowl LIV in the 2019 season but were defeated by the Kansas City Chiefs. The team has continued to be competitive, making playoff appearances and contending for division titles.\n",
      "\n",
      "8. **Community and Culture**: The 49ers are known for their strong fan base and community involvement. They have various charitable initiatives and programs aimed at giving back to the community, including the 49ers Foundation, which supports education and youth development programs.\n",
      "\n",
      "The 49ers continue to be a prominent and competitive team in the NFL, with a rich history and a bright future ahead. Their legacy is built on a tradition of excellence, innovation, and a passionate fan base."
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "--\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
    "\n",
    "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
    "\n",
    "--\n",
    "\n",
    "The LangGraph API [has first class support for streaming](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#streaming). \n",
    "\n",
    "Let's load our `agent` in the Studio UI, which uses `module-1/studio/agent.py` set in `module-1/studio/langgraph.json`.\n",
    "\n",
    "The LangGraph API serves as the back-end for Studio.\n",
    "\n",
    "We can interact directly with the LangGraph API via the LangGraph SDK.\n",
    "\n",
    "We just need to get the URL for the local deployment from Studio.\n",
    "\n",
    "![Screenshot 2024-08-27 at 2.20.34 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf8943c3d4df239cbf0f_streaming2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# Replace this with the URL of your own deployed graph\n",
    "URL = \"http://localhost:54900\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1ef7348c-ac8d-646c-bec0-fbf508bb03da'})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4163ab28-6145-40af-a884-dbb8f7101dcb', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4163ab28-6145-40af-a884-dbb8f7101dcb', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, 'type': 'ai', 'name': None, 'id': 'run-65504787-796a-4e25-8476-564f8103b99e', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4163ab28-6145-40af-a884-dbb8f7101dcb', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, 'type': 'ai', 'name': None, 'id': 'run-65504787-796a-4e25-8476-564f8103b99e', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '0973f69c-79cf-430e-9ece-a773a8d4430d', 'tool_call_id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4163ab28-6145-40af-a884-dbb8f7101dcb', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, 'type': 'ai', 'name': None, 'id': 'run-65504787-796a-4e25-8476-564f8103b99e', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '0973f69c-79cf-430e-9ece-a773a8d4430d', 'tool_call_id': 'call_Q3U2gbhFiGRmDHSr9WXNlrwi', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, 'type': 'ai', 'name': None, 'id': 'run-e45b5288-d199-4e9b-81de-86f1f4bdf787', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} response_metadata={} id='426b09e2-c2aa-46ae-8f5c-beeceb5e9014'\n",
      "=========================\n",
      "content='' additional_kwargs={'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_Lzs2tDj7njjFJA39pEZn79pG', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} response_metadata={} id='run-446de096-103a-4632-b33b-cb4e8d453a6c' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_Lzs2tDj7njjFJA39pEZn79pG', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='6d45170d-7ff8-405e-83e2-5596a9bbea61' tool_call_id='call_Lzs2tDj7njjFJA39pEZn79pG'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} response_metadata={} id='run-56ef9f2a-dd3a-4167-b964-7e25c1a9c364'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1ef73492-d411-6109-9b34-9fe11cd4cf4d\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_QoKVABfhKnepHf423fXeDEre, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
